{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. RUN CONFIG: FUNCTIONS, CONSTANTS, MODELS, ETC\n",
    "%run \"../config/config.ipynb\"\n",
    "\n",
    "list_dataset = [ds0]\n",
    "list_forecast_horizon = [fh1] # 30min ahead\n",
    "\n",
    "list_model_and_hp = [\n",
    "    [m1, 'hp1'],\n",
    "    [m2, 'hp2'],\n",
    "    [m3, 'hp1'],\n",
    "    [m4, 'hp1'],\n",
    "    [m5, 'hp1'],\n",
    "    [m6, 'hp1'],\n",
    "    [m7, 'hp1'],\n",
    "    [m8, 'hp1'],\n",
    "    [m9, 'hp3'],\n",
    "    [m10, 'hp1'],\n",
    "    [m11, 'hp1'],\n",
    "    [m12, 'hp1'],\n",
    "    [m13, 'hp1'],\n",
    "    [m14, 'hp1'],\n",
    "    [m15, 'hp1'],\n",
    "    [m16, 'hp1'],\n",
    "    [m17, 'hp1'],\n",
    "    [m18, 'hp1']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c9ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running m18_nbeats with hyperparameter hp1 on ds0_test.csv for forecast horizon 30\n",
      "Pass Test 1 - Forecast horizon is >= dataset frequency\n",
      "Pass Test 2 - Hyperparameter choice is possible given the forecast horizon\n",
      "Processing CV 1 / 10....\n",
      "\n",
      "Processing CV 2 / 10....\n",
      "\n",
      "Processing CV 3 / 10....\n",
      "\n",
      "Processing CV 4 / 10....\n",
      "\n",
      "Processing CV 5 / 10....\n",
      "\n",
      "Processing CV 6 / 10....\n",
      "\n",
      "Processing CV 7 / 10....\n",
      "\n",
      "Processing CV 8 / 10....\n",
      "\n",
      "Processing CV 9 / 10....\n",
      "\n",
      "Processing CV 10 / 10....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN BATCH FOR ALL COMBINATIONS\n",
    "for dataset in list_dataset:\n",
    "    for forecast_horizon in list_forecast_horizon:\n",
    "        for model_name, hyperparameter_no in list_model_and_hp:\n",
    "            print(f\"Running {model_name} with hyperparameter {hyperparameter_no} on {dataset} for forecast horizon {forecast_horizon}\")\n",
    "            dataset = dataset\n",
    "            forecast_horizon = forecast_horizon # fh1 = 30 minutes ahead, fh9 = 2 days ahead\n",
    "\n",
    "            # MODEL AND HYPERPARAMETER TO CHOOSE\n",
    "            model_name = model_name\n",
    "            hyperparameter_no = hyperparameter_no\n",
    "\n",
    "            # 3. PREPARE FOLDER\n",
    "            hyperparameter, experiment_no_str, filepath = prepare_directory(path_result, forecast_horizon, model_name, hyperparameter_no)\n",
    "\n",
    "            # 4. INPUT DATA\n",
    "            block_length, holdout_df, df = input_and_process(path_data_cleaned, forecast_horizon, max_lag_day, n_block)\n",
    "\n",
    "            # 5. RUN MODEL\n",
    "            run_model(df, model_name, hyperparameter, filepath, forecast_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519383dd",
   "metadata": {},
   "source": [
    "# Populate Last 18 Experiment Cross Validation Results For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7e49780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ..\\..\\experiment_result\\E00010_250818_ds0_fh30_m1_naive_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00011_250818_ds0_fh30_m2_snaive_hp2\n",
      "Extracting ..\\..\\experiment_result\\E00012_250818_ds0_fh30_m3_ets_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00013_250818_ds0_fh30_m4_arima_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00014_250818_ds0_fh30_m5_sarima_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00015_250818_ds0_fh30_m6_lr_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00016_250818_ds0_fh30_m7_ann_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00017_250818_ds0_fh30_m8_dnn_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00018_250818_ds0_fh30_m9_rt_hp3\n",
      "Extracting ..\\..\\experiment_result\\E00019_250818_ds0_fh30_m10_rf_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00020_250818_ds0_fh30_m11_svr_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00021_250818_ds0_fh30_m12_rnn_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00022_250818_ds0_fh30_m13_lstm_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00023_250818_ds0_fh30_m14_gru_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00024_250818_ds0_fh30_m15_transformer_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00025_250818_ds0_fh30_m16_prophet_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00026_250818_ds0_fh30_m17_xgb_hp1\n",
      "Extracting ..\\..\\experiment_result\\E00027_250818_ds0_fh30_m18_nbeats_hp1\n",
      "Exporting 20250819_test_result.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "exp_result_folder = '../../experiment_result/'\n",
    "benchmark_file = '../../experiment_result/Archive/Testing Result/testing_benchmark.csv'\n",
    "output_folder = '../../experiment_result/Archive/Testing Result/'\n",
    "\n",
    "# Get m1-m18 name\n",
    "\n",
    "# Create an empty Df\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Compute the number of folder in the experiment result folder \n",
    "def get_number_of_folders(path):\n",
    "    return len([name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))])\n",
    "\n",
    "# Get the number of folders in the experiment result folder\n",
    "number_of_folders = get_number_of_folders(exp_result_folder)\n",
    "n_experiments = number_of_folders - 1\n",
    "pos_first_naive = n_experiments - 18 + 1\n",
    "parent = Path(exp_result_folder)        # adjust\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for i in range(pos_first_naive, n_experiments + 1):        # 1 → n (change to 0-based if you need)\n",
    "    # “E” + 5-digit zero-padded index, e.g. 1 → E00001, 12 → E00012, 123 → E00123\n",
    "    pattern = f\"E{i:05d}_*\"                  # tail “_*” matches any suffix\n",
    "    for folder in parent.glob(pattern):      # returns Path objects for every match\n",
    "        print('Extracting ' + str(folder))                        # ↪ or os.chdir(folder) / open files here\n",
    "        \n",
    "        # Extract model name\n",
    "        \n",
    "        import re\n",
    "\n",
    "        match = re.search(r\"(m\\d+_[^_]+)\", str(folder))\n",
    "        if match:\n",
    "            model = match.group(1)\n",
    "        \n",
    "        try:\n",
    "            # any file that ends with “…_cross_validation_result[.csv]”\n",
    "            csv_path = next(folder.glob(\"*_cross_validation_result*.csv\"))\n",
    "            result_df = pd.read_csv(csv_path, header=0, skiprows=range(1, 11), nrows=2, index_col=0).T     #  result\n",
    "            \n",
    "            result_df = result_df.stack()\n",
    "            result_df.index = result_df.index.map(lambda x: f\"{x[0]}_{x[1]}\")\n",
    "            result_df = result_df.to_frame(name=\"value, test\")\n",
    "            result_df.index = model + \"_\" + result_df.index.astype(str)\n",
    "\n",
    "            summary_df = pd.concat([summary_df, result_df], axis=0)\n",
    "\n",
    "        except StopIteration:\n",
    "            print(f\"⚠️ no result file in {folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ error reading {folder}: {e}\")\n",
    "\n",
    "# Copy benchmark values\n",
    "benchmark_df = pd.read_csv(benchmark_file, index_col=0)\n",
    "\n",
    "summary_df = pd.concat([benchmark_df, summary_df], axis=1)\n",
    "\n",
    "summary_df['error_percent'] = (\n",
    "    (summary_df['value, test'] - summary_df['value, benchmark']) \n",
    "    / (summary_df['value, benchmark'] + 1e-8) * 100\n",
    ").round(2)\n",
    "\n",
    "summary_df['test_result'] = np.where(summary_df['error_percent'] < 5, 'pass', 'fail')\n",
    "\n",
    "# Create output file name\n",
    "\n",
    "\n",
    "output_file = f\"{date.today().strftime('%Y%m%d')}_test_result.csv\"\n",
    "\n",
    "# Output testing file result\n",
    "print('Exporting ' + output_file)  # e.g. 20250819_test_result.csv\n",
    "summary_df.to_csv(output_folder + output_file, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd310304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
